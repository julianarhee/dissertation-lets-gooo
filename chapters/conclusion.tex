\chapter{Conclusion}
\label{conclusion}
Across the animal kingdom, animals rely on a rich repertoire of behavior for their survival. From foraging ants to caching corvids, evidence for cognitive capacities abounds. Although basic neuroscience research has traditionally focused on a limited set of organisms, technological advances in both genetics and methods for recording in behaving animals make it increasingly possible to study neural processes of cognitive function in diverse species --- from ants\cite{Trible2017OrcoAnts} and flies\cite{Seelig2015,Haberkern2016}, to birds\cite{Clayton2009,Jarvis2014}, and even cephalopods\cite{Albertin2015, Crawford2020}. However, this has only become possible in recent years. Even in more traditional animal models of cognition, insight into mechanistic understanding has always lagged behind the discovery and parameterization of behavioral and neural phenomena.

Visual object recognition is a computationally challenging problem that remains unsolved. Most studies are in humans and monkeys, which are experimentally much less tractable. In recent years, rodents have emerged as powerful systems in which to study visual circuits. There are increasingly sophisticated genetic tools, such as cell-type-specific targeting of single cells, and optical imaging techniques, including multi-photon imaging and  holographic stimulation, that are available for studying the neural circuits associated with a given behavior. A growing number of studies in the mouse have demonstrated the power of these tools for functional dissection of microcircuits, from access to and manipulation of genetically-defined cell types to massively large-scaled population recordings during a trained behavior.

Chronic, large-scale, cellular-resolution imaging forms a class of approaches that have proved immensely powerful for dissecting neural circuits. Despite rats’ amazing behavioral capacities, few paradigms exist for applying these methods to head-fixed, behaving rats. While systems that combine freely moving behavior with tethered or wireless recordings are rapidly improving and highly valuable, awake, head-fixed systems are beneficial for careful stimulus delivery, behavioral monitoring, and chronic preparations that allow for longitudinal studies in which the same cells can be tracked across many days.   

\section{Summary of findings} 
\paragraph{High-throughput visual behavior in rats.}  Rats exhibit complex behaviors in the field and in the lab. Training rats on complicated tasks takes a great deal of time and labor, and there is little standardization across labs. In Chapter 1, I presented OpenRatBox, a modular, low-cost, and open-source platform for training large cohorts of rats on a range of visual tasks. With this behavior system, we showed that large cohorts of rats can be trained (>50 animals), in parallel, on complex visual tasks that typically take about a month to train. Using this system, we tested the perceptual behaviors of trained rats in response to various transformations of complex object stimuli, which could then be tested for neural imaging experiments. 

\paragraph{Optical imaging systems in awake, head-fixed rats.}  Armed with a high-throughput method for training rats on visual behaviors, we next established a suite of tools for optical imaging in awake, head-fixed rats. In Chapter 2, I described an optimized pipeline for cellular resolution imaging in highly lateral regions of the rat visual cortex, while the animal is awake and head-restrained. The imaging system allows the same cells in a given FOV to be tracked across multiple days of recording, which is a critical advantage, as rats are the model of choice for the study of many cognitively demanding behaviors. I also demonstrate the feasibility of imaging multiple visual areas at once, with the extra large fields-of-view to accommodate access to the larger brains of rats. The developments described in this chapter overcome challenges that have precluded the rat as a standard model not only for the study of visual circuits, but more broadly, for the use of powerful genetic tools that combine large-scale cellular, resolution recording and manipulation in studies of cognitive behaviors.

\paragraph{Characterizations of rat extrastriate cortex.}  As the first demonstration of optical imaging in extrastriate regions of rat cortex, it was important to contribute baseline metrics of neural responses in the targeted areas of rat visual cortex. Rats are one of the first non-primate species in which both behavioral and neurophysiological signatures of invariant object recognition have been found, so I selected a subset of these identified visual areas in the rat, areas V1, LM and LI, for the present study. In Chapter 3, I presented a systematic survey of visual response properties across these three visual areas. 

Consistent with previous studies of rodent visual cortex, I found increasing receptive field sizes in extrastriate areas. Interestingly, I also observed several forms of anisotropy in the visual field representations of all areas measured. Cortical magnification was greater along elevation than azimuth, meaning that rat visual cortex contains expanded representations of the vertical dimension of visual field space. Receptive fields were also elongated along the horizontal axis, raising the possibility that anisotropic receptive fields facilitate a higher resolution representation along elevation. Finally, I also found asymmetries in retinotopic scatter: although scatter was greater along elevation for all visual areas, it was not proportional to the asymmetric cortical magnification in LM and LI, as it was in V1. Rather, scatter in elevation was lower than expected, suggesting higher fidelity representations in elevation. Many of these asymmetries and anisotropies in how visual cortex represents the animal's visual field have been discovered in the mouse, as well\cite{Marshel2011, Bonin2011, Juavinett2017,Zhuang2017,Murgas2020,Sit2020}. Together, these findings raise the possibility of alternative mechanisms for enhanced representations in a non-foveating animal. With the development of head-mounted, eye-tracking acquisition systems\cite{Meyer2020, Michaiel2020}, it is possible to explore these observations further in both mice and rats. 

In addition to biased visual field representations, I found strong axis tuning in V1. Consistent with previous studies in mice, there was an over-representation of cells preferring cardinal axes, especially for horizontally-oriented or vertically-moving gratings. Relative to primates, rodents likely experience different visual statistics, and the biases in edge motion and receptive fields could reflect non-uniform changes in the visual field as an animal runs around close to the ground. 

In contrast to what might be expected from a purely primate-like ventral stream area, concerned primarily with visual form, I found greater direction tuning in LI than V1 or LM. This is consistent with \citet{Vermaercke2014}, as well as studies of mouse POR, which provide evidence for specialized motion processing pathways in lateral extrastriate areas in rodents. Furthermore, observations of higher shape discriminability in LI relative to V1\cite{Vermaercke2014,Froudarakis2020} was observed using moving stimuli. Visual object recognition in rodents may thus be closely tied to motion processing --- given that animals navigate in complex, dynamic environments, studies in rodents raise the exciting possibility that traditionally separate functional pathways might be more closely entwined than in the primate brain. To date, most studies have not found the same, clearly-defined separation between proposed ``layers'' of the rodent visual hierarchy. Although a growing body of evidence supports this idea, it is also likely that there are fundamental differences in how rodent and primate visual systems are organized. 

\section{Comparison with existing methods}
Electrophysiology is commonly used in rats, and in awake, freely-moving animals, provides a powerful preparation for studying neural activity in the context of complex and naturalistic behaviors, as the animal need not be restrained. However, chronic access to the same cells across long periods of time, such as over the course of learning, is challenging and difficult to verify with existing electrophysiology methods. Furthermore, although increasingly higher-density probes may improve the resolution of recording, they can damage neural tissue, and fine-scale, cell-type-specific manipulations are much harder to control (as opposed to, say, holographic stimulation). Importantly, most non-optical methods are blind to the particular cell-types being recorded from, which thus places an inherent limit to the level of mechanism that one can reach with existing methods.

For optical imaging, many groups have had success with combining fiber-based systems or head-mounted wireless scopes in freely moving rats. Indeed, the larger size of the rat has been advantageous, as larger devices can be affixed to the skull for chronic, long-term imaging. However, there is usually trade-off between having a small FOV with cellular resolution (head-mountable scope) or a larger FOV without cellular resolution (single-photon). Moreover, in order to access lateral cortex on the side of the animal’s head, head-mounted preparations are difficult to maintain in a stable way, while keeping the animal comfortable enough to perform a behavioral task. For head-fixed preparations, \citet{Scott2013} stand out:  they successfully trained rats to voluntary head-fix themselves for cellular resolution imaging during trained behavior. However, this involves time-intensive and laborious training, and data acquisition is less under experimenter control. 

The present set of studies overcomes many of these trade-offs and demonstrates the feasibility of high-resolution, large-FOV imaging with cellular resolution in awake, head-fixed rats. The head-fixed system is also synced with an auxiliary imaging system for simultaneous, high-resolution tracking of animal’s facial movements and behaviors. Although head-fixing the animal comes at the cost of studying neural activity under more naturalistic conditions, it comes with the benefit of reducing the parameter space of behaviors that are already highly complex and multi-dimensional, even in the absence of any stimulus\cite{Stringer2019spontaneous}. Moreover, when stimuli are used, head-fixing allows extremely precise retinal monitoring and stimulus control. Finally, head-fixing facilitates experiments in which the same populations of cells is tracked from day to day. Nonetheless, animals are not normally interacting with stimuli in fixed positions, and animals are rarely in static behavioral states. As such, future experiments investigating how different behavior states and task conditions modulate visual object representations will be immensely valuable for understanding how visual cortex and sub-cortical circuits together support perception.

\section{Comparison with previous studies}
All studies of lateral extrastriate cortex have used extracellular electrophysiology.
\citet{Vermaercke2014} recorded in awake, head-fixed, naive rats, similar to the present study. They found that linear decoding accuracy for static images (simple shapes presented at a given position) were best in V1, while LM and LI accuracies were barely above chance. Matching for the same pseudo-population sizes (N=64 cells), I found discriminability to be comparable across all areas under study (V1, LM, and LI) and well above chance. This could be due to differences in stimuli, as they use simple stimuli composed of oriented edges (such as triangles, squares), while I used slightly more complex, pseudo-3D object stimuli. 

\citet{Tafazoli2017} used stimuli similar to the ones used here, but recorded in anesthetized, head-fixed rats. Overall, they found the best decoding and discriminability in area LL, which was not included in the studies presented here. However, their findings in areas V1, LM, and LI are consistent with what I observed:  across areas V1, LM and LI, they found that classifier accuracies on tests of linear separability and generalization were comparable, though LI generalization was greater than that of V1 and LM. Consistent with this, I found that all linear classifiers trained to discriminate object stimuli from the activity in each of the three areas performed comparably, and LI was the most robust to generalization tests across size.

% Interestingly, they also found that LM accuracies were the worst overall, ~5-8\% lower classifier accuracy than V1 and LI. I found a similar pattern of results, with LM accuracy ~8\% lower than V1 and LI) when matching for pseudo-population size (n=96 cells), as does \citet{Vermaercke2014}, with LM performing the worst in discriminating static images. Absolute accuracy levels were higher in our study and Vermaerke et al., compared to accuracy levels reported for a subset of conditions by Tafazoli et al. (pseudo-population, n=96 cells). This could be due to differences in behavioral state (Tafazoli et al. recorded in anesthetized rats) or differences in stimuli (Tafazoli et al average across a much more diverse and complex array of object images). 

\citet{Froudarakis2020} showed that mice may be capable of the type of object recognition tasks used to train rats. Though overall accuracy in mice falls short of the accuracy levels found in our trained rats, generalization is robust. This study also recorded in awake animals using two-photon imaging. Interestingly, they find LM and AL to be the most robust to transformation. In contrast, I found that discriminability, as measured by classifier accuracy, was fairly constant across the range of stimuli and visual areas tested. However, the studies described here only examined areas V1, LM, and LI. In contrast, \citet{Tafazoli2017} identified area LL and \citet{Vermaercke2014} identified area TO as the most ``IT''-like, two areas that have not been investigated in mouse or in the present study. Areas LL and TO lie further laterally than LM and LI in rats. Direct mapping between mouse and rat visual areas remains unresolved and requires further investigation. Systematization of stimulus type, behavior state, and recording methods would allow more direct comparisons between rat and mouse descriptions of the ventral-like pathway to determine whether the two species exhibit different functional organization. 

Interestingly, \citet{Froudarakis2020} used dynamic movie stimuli as opposed to static images while recording in awake, head-fixed mice. Many of the functional specializations of rodent visual areas are still being characterized. However, motion processing appears to be particularly significant, even in higher-order areas of visual cortex that were previously associated with the ``what'' as opposed to ``where'' pathways of the brain. Broadly, it is exciting to consider the extent to which rodent visual cortex might deviate from the traditional primate framework. 

% Both \citet{Froudarakis2020} and \citet{Tafazoli2017} tested multiple types of identity-preserving transformations, and consistent with our results, that LI appears more robust to size transformations, both studies find that LI tends to exhibit some improvement beyond V1, depending on the particular transformation. 

\section{Future directions}
% Though the present study presented with many technical difficulties, one consistent challenge was consistent identification of area LL. Area LL is notable because previous studies measured electrophysiological responses , There are several possibilities, which we address now. For example, using many injections of viral GCaMP to cover the cranial window proved to be much more time-consuming and less efficient than desired. Small patches in viral expression preclude us from unambiguously identifying similarly small visual areas. This problem can be overcome by recently developed transgenic animals that express GCaMP in all neurons\cite{Scott2018}. It is unlikely that visual responses in area LL were completely unresponsive to any of the stimuli presented, from the cycling bar stimulus and the receptive field tiling protocols, to the drifting gratings and object stimuli. In a subset of animals, we did identify area LL, but only as putative LL, since LL identification here was relative to only one visual area, namely, LM. As quantified \citet{Juavinett2017}, several of the smaller extrastriate visual areas that are several borders removed from V1, require multiple abutting regions to also be identified for confident estimations. Our surgical and technical developments from Chapter 2 combined with imaging in transgenic rats will likely improve future attempts to reliably identify area LL. 

\paragraph{Imaging in trained, behaving rats.} Currently, mice are one of the most commonly used models for combining cellular resolution imaging and manipulation in behaving animals. Although rats are an equally popular model system across many fields of neuroscience, such techniques have remained challenging to apply to larger rodent models. One of the most natural extensions of this work is to combine a behavioral task while the rat is head-fixed. Pilot data suggests that rats can and will learn a two-choice discrimination task: I trained rats using a custom-built, rat-sized version of the International Brain Lab's steering wheel method (Carandini/Harris Labs, UCL), and rats will engage in Go/No-Go and even two-port tasks while head-fixed. Since our rats were calm and showed signs of distress largely only at the start of habituation, I do not foresee training and behaving animals as an insurmountable step. Expanding on this, many of the existing genetic tools used in mice can be used in rats, from cell-specific stimulation to multi-color functional imaging that tracks defined populations of cells over the course of learning or performing a behavior. 

\paragraph{State modulation and cell-type selectivity.} Behavioral evidence in rats suggests that, although rats can and do generalize robustly across a large range of transformations, performance is modulated by task-specific strategies\cite{Djurdjevic2018,Masis2020}. In addition, previous studies have shown that different visual areas may generalize better or worse, depending on the particular transformation tested\cite{Vermaercke2014, Tafazoli2017, Froudarakis2020}. Given known effects of arousal modulation and biases in feature tuning across visual areas and cell types, it would be interesting to identify how behavior state and task demands specifically modulate cell populations with known functional selectivity (for example PV+ or SOM+ interneurons), and how this propagates to downstream, high-level representations. With this, a more thorough investigations of simple feature representations of rat visual cortex would be valuable, especially in the context of cell-type specific computations as have been found in mouse visual cortex.

\paragraph{Natural(istic) visual statistics and active vision.} Many of the studies characterizing the hierarchical organization of primate visual cortex have relied on naive, passively-viewing monkeys. As such, recording in naive rodents does allow a valuable point of comparison between the species, as they likely experience dramatically different visual statistics during development. Nonetheless, presenting static, artificial stimuli in head-fixed rats is a highly unnatural condition. It is unlikely that static views of bright objects on dark screens is a familiar sight in the visual world of rodents, as these are animals that run about along the ground and in fields. On one hand, recording in head-fixed rats that are either already trained, or better yet, engaged in the object recognition task, is likely to produce more relevant and accurate characterizations of how the rat visual brain solves the problem of visual object recognition. On the other hand, more naturalistic stimuli that combine motion statistics with object recognition may be more relevant, albeit more complicated, stimuli for studying rodent visual cortex.

While the present study relies on the advantages of head-fixed preparations and largely static visual stimuli, vision is a dynamic and active process. Thus, an additional important directions is to bring traditional visual studies closer to more naturalistic behaviors. First, many groups have made significant progress imaging with optical imaging in freely moving rats, and a growing number are able to acquire two-photon imaging by mounting small microscopes on the rat's head. Comparing how the animal uses eye- and head-movements during active vision, that is, during freely moving behavior, and how visual representations compare to when animals are exposed to the same visual stimuli in a passive, head-fixed state (\textit{i.e.}, visual playback), may be a promising paradigm to tease apart contributions of active and passive components of vision. In a similar vein, using a continuous-reporting paradigm, such as the steering wheel described above, rats can be trained to use a closed-loop stimulus that it controls with the wheel (or joystick) to generate particular views of a given object. For example, rats can be trained to associate a particular default stimulus view with a reward, after which point, it must use a physical rotation (with the steering wheel) to rotate a new, different view of the object back around to the trained view. Thus, rather than presenting static 2D images of different 3D objects, the head-fixed preparation combined with a self-generated visual stimulus could provide a more direct readout of the animal's perceptual experience, which could be measured simultaneously in the neural population. This would effectively provide an intermediate mode between active and passive vision.

\paragraph{Comparative studies.}  The widespread use of mouse models in many areas of systems neuroscience has led to many discoveries in cortical function, sensory processing, and cognitive function. However, many existing tools can be applied in related rodent models, beyond rats. For example, among rodents, squirrels\cite{VanHooser2006,Campi2010ComparativeNumber} are more visual, categorized as diurnal animals, and thus would provide a valuable point of comparison to existing rodent models that are arguably less visual under natural conditions. In addition, other mouse species, like \textit{Peromyscus}, exhibit highly complex and interesting behaviors with identified genetic causes\cite{Metz2017,Jourjine2021}. Broader use of tools in models beyond the standard \textit{Mus musculus} would not only be interesting in itself, but would allow researchers to identify many diverse solutions to important biological problems.

\section{Concluding remarks}
One of the most exciting avenues in systems neuroscience research today is the ability to study neural circuits simultaneously with behavior over the course of learning. Despite rats being the standard model for studies of learning and memory, few studies have been able to track the same cells over time in rats learning these complex tasks. Almost 100 years ago, \citet{Lashley1938} discovered pattern recognition capacities in rats. About a decade ago, \citet{Zoccolan2009} demonstrated that rats are capable of invariant object recognition, a behavior that was long considered to be unique to primates. Ten years later, \citet{Froudarakis2020} have shown that mice, too, are capable of this complex visual behavior. Although a great deal has been learned about how a biological system solves this important problem of perception, many questions remain. The study of multiple rodent models offers a promising alternative by which both general principles and species-specific adaptations can be discovered. 

Understanding how the brain builds up visual object representations has the potential to inform not only how we perceive the things in our world, but more broadly, how a wild disarray of sensory information can be transformed into complex representations that can guide meaningful behavior. The many similarities between primate and rodent visual systems suggest that what is learned in one may be found in the other. However, many aspects of the rodent visual system are likely species-specific, and a comparative approach has the promise to reveal both general principles of neural organization as well as species-specific adaptations that reveal how organisms adapt and evolve in different environments. 

Beyond vision, our study closes a long-standing gap to unlock the rat as a powerful model system for systems neuroscience. The technological advancements presented in this work have the potential to unlock a wide range of new experimental directions, enabled by the superior molecular and genetic tools available in rodents. These studies overcome significant barriers and open the way toward mechanistic studies in a powerful model for cognitive behaviors.