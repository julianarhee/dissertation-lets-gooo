\chapter{Conclusion}
\label{conclusion}
Visual object recognition is a computationally challenging problem that remains unsolved. Most studies are in humans and monkeys, which are experimentally much less tractable. In recent years, rodents have emerged as powerful systems in which to study visual circuits. There are increasingly sophisticated genetic tools, such as cell-type-specific targeting of single cells, and optical imaging techniques, including multi-photon imaging and  holographic stimulation, that are available for studying the neural circuits associated with a given behavior. A growing number of studies in the mouse have demonstrated the power of these tools for functional dissection in mice, from access to and manipulation of genetically-defined cell types to massively large-scaled population recordings during a trained behavior.

Chronic, large-scale, cellular-resolution imaging forms a class of approaches that have proved immensely powerful in dissecting neural circuits. Despite rats’ amazing behavioral capacities, few paradigms exist for applying these methods to visual circuits of head-fixed, behaving rats. While systems that combine freely moving behavior with tethered or wireless recordings are rapidly improving and highly valuable, awake, head-fixed systems are beneficial for careful stimulus delivery, behavioral monitoring, and chronic preparations that allow for longitudinal studies in which the same cells can be tracked across many days.   

\section{Summary of findings} 
\subsection{High-throughput visual behavior in rats}
Rats exhibit complex behaviors in the field and in the lab. Training rats on complicated tasks takes a great deal of time and labor, and there is little standardization across labs. In Chapter 1, I presented OpenRatBox, a modular, low-cost, and open-source platform for training large cohorts of rats on a range of visual tasks. With this behavior system, we showed that large cohorts of rats can be trained (>50 animals), in parallel, on complex visual tasks that typically take about a month to train. Using this system, we tested the perceptual behaviors of trained rats in response to various transformations of complex object stimuli, which could then be tested for neural imaging experiments. 

\subsection{Optical imaging systems in awake, head-fixed rats}
Armed with a high-throughput method for training rats on visual behaviors, we next established a suite of tools for optical imaging in awake, head-fixed rats. In Chapter 2, I described an optimized pipeline for cellular resolution imaging in highly lateral regions of the rat visual cortex, while the animal is awake and head-restrained. The imaging system allows the same cells in a given FOV to be tracked across multiple days of recording, which is a critical advantage, as rats are the model of choice for the study of many cognitively demanding behaviors. I also demonstrate the feasibility of imaging multiple visual areas at once, with the extra large fields-of-view to accomodate access to the larger brains of rats. The developments described in this chapter overcome challenges that have precluded the rat as a standard model not only for the study of visual circuits, but more broadly, for the use of powerful genetic tools that combine large-scale cellular, resolution recording and manipulation in studies of cognitive behaviors.

\subsection{Basic characterizations of rat extrastriate cortex}
As the first demonstration of optical imaging in extrastriate regions of rat cortex, it was important to contribute baseline metrics of neural responses in the targeted areas of rat visual cortex. Rats are one of the first non-primate species in which both behavioral and neurophysiological signatures of invariant object recognition have been found, so I selected a subset of these identified visual areas in the rat, namely, areas V1, LM and LI, for the present study. In Chapter 3, I presented a systematic survey of visual response properties across these three visual areas. 

Consistent with previous studies of rodent visual cortex, I found increasing receptive field sizes in extrastriate areas. Interestingly, I also observed several forms of anisotropy in the visual field representations of all areas measured. Cortical magnification was greater along elevation than azimuth, meaning that rat visual cortex contains expanded representations of the vertical dimension compared to the horizontal dimension. I also found that receptive fields were elongated along the horizontal axis, raising the possibility that these anistropic receptive fields facilitate a higher resolution representation of the vertical dimension. Finally, I also found asymmetries in retinotopic scatter: although scatter was greater along elevation for all visual areas, it was not proportional to the asymmetric cortical magnification in LM and LI, as it was in V1. Rather, scatter in elevation was lower than expected, suggesting higher fidelity representations in elevation. Together, these findings raise the possibility of an alternative mechanism for enhanced representations in a non-foveating animal. With the development of head-mounted, eye-tracking acquisition systems\cite{Meyer2020, Michaiel2020}, it is possible to explore these observations further in both mice and rats. 

In addition to biased visual field representations, I also found strong axis tuning and selectivity in V1, and consistent with previous studies in mice, there was an over-representation of cells preferring cardinal axes, especially for horizontally-oriented or vertically-moving gratings. Relative to primates, rodents likely experience different visual statistics, and the biases in edge motion and receptive fields could reflect non-uniform changes in the visual field as an animal runs around close to the ground. 

I also found greater direction tuning in LI than might have been expected from a purely higher-order area like primate IT. Consistent with \citet{Vermaercke2014}, I found greater direction tuning in LI than in earlier visual areas. These results suggests that lateral extrastriate cortex may be more tuned to motion or moving stimuli than a standard ``primate-like'' object recognition pathway. Furthermore, higher shape discriminability, relative to V1, that was observed in both awake rats\cite{Vermaercke2014} and mice\cite{Froudarakis2020}, was measured using moving stimuli. It is possible that visual object recognition in rodents is closely tied to motion statistics --- given that animals navigate in complex, dynamic environments, studies in rats and mice raise the exciting possibility that traditionally separate ideas, such as the ``what'' and ``where'' pathways, might have closer ties than previously appreciated in the primate brain. 

To date, most studies have not found the same, clearly-defined separation between proposed ``layers'' of the rodent visual hierarchy. Although a growing body of evidence supports this idea, it is also likely that there are fundamental differences in how these visual systems are organized. 

\section{Comparison with existing methods}
Typically, rats are used in freely-moving or unrestrained paradigms. Electrophysiology is commonly used in rats, and in awake animals, provides a powerful preparation for studying neural activity in the context of complex and naturalistic behaviors, as the animal need not be restrained. However, chronic access to the same cells across long periods of time, such as over the course of learning, is challenging and difficult to verify. Furthermore, although increasingly higher-density probes may improve the resolution of recording, they can damage neural tissue, and fine-scale, cell-type-specific manipulations are much harder to control (as opposed to, say, holographic stimulation).  

For optical imaging, the larger size of the rat has been advantageous, as head-mounted scopes can be affixed to the skull for chronic, long-term imaging. However, there is usually trade-off between having a small FOV with cellular resolution (head-mountable scope) or a large FOV without cellular resolution (single-photon). Moreover, in order to access lateral cortex on the side of the animal’s head, head-mounted preparations are difficult to maintain in a stable way. \citet{Scott2013} successfully trained rats to voluntary head-fix themselves for cellular resolution imaging during trained behavior. However, this involves time-intensive and laborious training, and data acquisition is less under experimenter control. 

The present set of studies overcomes many of these trade-offs and demonstrates the feasibility of high-resolution, large-FOV imaging with cellular resolution in awake, head-fixed rats. I leverage the head-fixed system to simultaneously track high-resolution video of the animal’s facial movements and behaviors. Although head-fixing the animal comes at the cost of studying neural activity more natural conditions, it comes with the benefit of reducing the paramater space of already highly complex behaviors. Moreover, for studies of visual behavior, head-fixing always extremely precise retinal monitoring and stimulus control, all while returning to the same populations of cells from day to day. Nonetheless, animals are not engaged in a fixed position, let alone a fixed behaviorial state, when interacting with objects in the world. As such, future experiments should continue to investigate how different behavior states and task conditions modulate the extent to which neural representations can or cannot support complex behaviors such as invariant object recognition.

\section{Comparison with previous studies in rodents}
\citet{Vermaercke2014} used electrophysiology to record from awake, head-fixed, naive rats, similar to the present study. They found that linear decoding accuracy for static images (simple shapes presented at a given position) were best in V1, while LM and LI accuracies were barely above chance. In contrast, matching for the same pseudo-population sizes (N=64 cells), I found discriminability to be comparable across all areas under study (V1, LM, and LI) and well above chance. This could be due to differences in stimuli, as they use simple stimuli composed of oriented edges (such as triangles, squares), while we use slightly more complex, pseudo-3D object stimuli.

\citet{Tafazoli2017} also recorded in naive rats with electrophysiology, but used stimuli similar to the ones used here, and recorded in anesthetized, head-fixed rats. Overall, they found significant improvements in all metrics tested for area LL, which was not included in the studies presented here. However, their findings in areas V1, LM, and LI are consistent with what I observed here. They found that across areas V1, LM and LI, classifier accuracies on tests for linear separability and generalization were comparable, though LI performance was significantly greater than that of V1 and LM. Consistent with this, I found that of the three areas tested, LI was the most robust to generalization tests across size.

% Interestingly, they also found that LM accuracies were the worst overall, ~5-8\% lower classifier accuracy than V1 and LI. I found a similar pattern of results, with LM accuracy ~8\% lower than V1 and LI) when matching for pseudo-population size (n=96 cells), as does \citet{Vermaercke2014}, with LM performing the worst in discriminating static images. Absolute accuracy levels were higher in our study and Vermaerke et al., compared to accuracy levels reported for a subset of conditions by Tafazoli et al. (pseudo-population, n=96 cells). This could be due to differences in behavioral state (Tafazoli et al. recorded in anesthetized rats) or differences in stimuli (Tafazoli et al average across a much more diverse and complex array of object images). 

\section{Comparison with other species}
\citet{Froudarakis2020} is the only study to show that mice may be capable of the type of object recognition tasks used to train rats. Although overall performance in mice falls short of the accuracy levels we found in our trained rats, generalization appears robust. Their study provides a valuable point of comparison as they also record in awake, passively-viewing animals using two-photon imaging. \citet{Froudarakis2020} find LM and AL to be the most robust to transformations, whereas \citet{Tafazoli2017} point to area LL as the most ``IT''-like. Area LL is a region lateral to LI in rats, but not tested in the mouse study, so future studies may help identify additional extrastriate areas that exhibit features thought to be important for visual object recognition.  In contrast, I found that discriminability, as measured by classifier accuracy, was fairly constant across the range of stimuli and visual areas tested. 

Interestingly, \citet{Froudarakis2020} used dynamic movie stimuli as opposed to static images while recording in awake, head-fixed mice. Many of the functional specializations of rodent visual areas are still being characterized. However, motion processing appears to be particularly signficant, even in higher-order areas of visual cortex that were previously associated with the ``what'' as opposed to ``where'' pathways of the brain. In short, it is likely that many of the traditional frameworks that have facilitated our understanding of initial forrays into the study of other visual systems may become less applicable as more mechanistic insights are revealed.

% Both \citet{Froudarakis2020} and \citet{Tafazoli2017} tested multiple types of identity-preserving transformations, and consistent with our results, that LI appears more robust to size transformations, both studies find that LI tends to exhibit some improvement beyond V1, depending on the particular transformation. 

\section{Future directions}
% Though the present study presented with many technical difficulties, one consistent challenge was consistent identification of area LL. Area LL is notable because previous studies measured electrophysiological responses , There are several possibilities, which we address now. For example, using many injections of viral GCaMP to cover the cranial window proved to be much more time-consuming and less efficient than desired. Small patches in viral expression preclude us from unambiguously identifying similarly small visual areas. This problem can be overcome by recently developed transgenic animals that express GCaMP in all neurons\cite{Scott2018}. It is unlikely that visual responses in area LL were completely unresponsive to any of the stimuli presented, from the cycling bar stimulus and the receptive field tiling protocols, to the drifting gratings and object stimuli. In a subset of animals, we did identify area LL, but only as putative LL, since LL identification here was relative to only one visual area, namely, LM. As quantified \citet{Juavinett2017}, several of the smaller extrastriate visual areas that are several borders removed from V1, require multiple abutting regions to also be identified for confident estimations. Our surgical and technical developments from Chapter 2 combined with imaging in transgenic rats will likely improve future attempts to reliably identify area LL. 
Given the goal of systematically characterizing a broad range of stimulus types, the work presented here is limited in the small sampling of any one class of visual stimulus. Compared to previous studies of visual object representations in rodents, I only tested a handful of object stimuli. As such, it is difficult to identify the extent to which the results of Chapter 4 are generalizable across different types of transformations. Given that previous studies have shown that there are asymmetries across transformations in separability and generalization, future work can investigate the extent to which there are interactions in the types of tolerant representations a given visual area can support. For example, given that arousal modulates gain and tuning of simple feature detectors like V1 cells, it would be interesting to investigate how arousal modulations of simple features propagates to downstream, high-level representations. Similarly, a more thorough investigations of simple feature representations of rat visual cortex would be valuable, especially in the context of cell-type specific computations as have been found in mouse visual cortex.

Although I imaged in awake, head-fixed rats, recordings were in naive, passively viewing animals. Presenting static, artifical stimuli in head-fixed rats is highly unnatural condition, despite the fact that this is the traditional method of visual stimulus presentation in primate vision studies. Many of the studies characterizing the hierarchical organization of primate visual cortex have relied on naive, passively-viewing monkeys. As such, recording in naive rodents does allow a valuable point of comparison between the species, as they likely experience dramatically different visual statistics during development. Nonetheless, it is unlikely that static views of bright objects on dark screens is a familiar sight in the visual world of rodents, as these are animals that run about along the ground and in fields. Thus, recording in head-fixed rats that are either already trained, or better yet, engaged in the object recognition task, is likely to produce more relevant and accurate cahracterizations of how the rat visual brain solves the problem of visual object recognition. 

Currently, mice are one of the most commonly used models in studies that leverage the power of cellular resolution imaging with genetic tools in awake animals. Although rats are an equally popular model system across many fields of neuroscience, such techniques have remained challenging to apply to larger rodent models. One of the most natural extensions of this work is to combine a behavioral task while the rat is head-fixed. Pilot data suggests that rats can and will learn a two-choice discrimination task: I trained rats using a custom-built, rat-sized version of the International Brain Lab's steering wheel method (Carandini/Harris Labs, UCL), and rats will engage in Go/No-Go and even two-port tasks while head-fixed. Since our rats were calm and showed signs of distress largely only at the start of habituation, I do not foresee training and behaving animals as an unsurmountable step. Expanding on this, many of the existing genetic tools used in mice can be used in rats, from cell-specific stimulation to multi-color functional imaging that tracks defined populations of cells over the course of learning or performing a behavior. 

While the present study relies on the advantages of head-fixed preparations and largely static visual stimuli, vision is a dynamic and active process. Thus, an additional important directions is to bring traditional visual studies closer to more naturalistic behaviors. First, many groups have made significant progress imaging with optical imaging in freely moving rats, and a growing number are able to acquire two-photon imaging by mounting small microscopes on the rat's head. Comparing how the animal uses eye- and head-movements during active vision, that is, during freely moving behavior, and how visual representations compare to when animals are exposed to the same visual stimuli in a passive, head-fixed state (\textit{i.e.}, visual playback), may be a promising paradigm to tease apart contributions of active and passive components of vision. In a similar vein, using a continuous-reporting paradigm, such as the steering wheel described above, rats can be trained to use a closed-loop stimulus that it controls with the wheel (or joystick) to generate particular views of a given object. For example, rats can be trained to associate a particular default stimulus view with a reward, after which point, it must use a physical rotation (with the steering wheel) to rotate a new, different view of the object back around to the trained view. Thus, rather than presenting static 2D images of different 3D objects, the head-fixed preparation combined with a self-generated visual stimulus could provide a more direct readout of the animal's perceptual experience, which could be measured simultaneously in the neural population. This would effectively provide an intermediate mode between active and passive vision.

\section{Concluding remarks}
One of the most exciting avenues in systems neuroscience research today is the ability to study neural circuits simultaneously with behavior over the course of learning. Despite rats being the standard model for studies of learning and memory, few studies have been able to track the same cells over time in rats learning these complex tasks. Over a decade ago, Zoccolan et al. (2009) demonstrated that rats are capable of invariant object recognition, a behavior that was long considered to be unique to primates. Ten years later, Froudarakis \textit{et al.} have shown that mice, too, are capable of this complex visual behavior\cite{Froudarakis2020}. Although a great deal has been learned about how a biological system solves this problem, many questions remain that are unfeasible to ask in primates, and rodent models offer a promising alternative by which both general principles and species-specific adaptations can be discovered. 

Understanding how the brain builds up visual object representations has the potential to inform not only how we perceive the things in our world, but more broadly, how a wild disarray of sensory information can be transformed into complex representations that can guide meaningful behavior. The many similarities between primate and rodent visual systems suggest that what is learned in one may be found in the other. However, many aspects of the rodent visual system are likely species-specific, and a comparative approach has the promise to reveal both general principles of neural organization as well as species-specific adaptations that reveal how organisms adapt and evolve in different environments. 

Beyond vision, our study closes a long-standing gap to unlock the rat as a powerful model system for systems neuroscience. The technological advancements presented in this work have the potential to unlock a wide range of new experimental directions, enabled by the superior molecular and genetic tools available in rodents. These studies overcome significant barriers and open the way toward mechanistic studies in a powerful model for cognitive behaviors.