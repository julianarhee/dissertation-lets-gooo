\chapter{Conclusion}
\label{conclusion}

Visual object recognition is a computationally challenging problem that remains unsolved. Most studies are in humans and monkeys, which are experimentally much less tractable. In recent years, rodents have emerged as powerful systems in which to study visual circuits. There are increasingly sophisticated genetic tools, such as cell-type-specific targeting of single cells, and optical imaging techniques, including multi-photon imaging and  holographic stimulation, that are available for studying the neural circuits associated with a given behavior. A growing number of studies in the mouse have demonstrated the power of these tools for functional dissection in mice, from access to and manipulation of genetically-defined cell types to massively large-scaled population recordings during a trained behavior.

Chronic, large-scale, cellular-resolution imaging forms a class of approaches that have proved immensely powerful in dissecting neural circuits. Despite rats’ amazing behavioral capacities, few paradigms exist for applying these methods to visual circuits of head-fixed, behaving rats. While systems that combine freely moving behavior with tethered or wireless recordings are rapidly improving and highly valuable, awake, head-fixed systems are beneficial for careful stimulus delivery, behavioral monitoring, and chronic preparations that allow for longitudinal studies in which the same cells can be tracked across many days.   


\section{Summary of findings} 
\subsection{High-throughput visual behavior in rats}
Rats exhibit complex behaviors in the field and in the lab. Training rats on complicated tasks takes a great deal of time and labor, and there is little standardization across labs. In Chapter 1, we presented a modular, low-cost, and open-source platform for training large cohorts of rats on a range of visual tasks. With our behavior system, we show that large cohorts of rats can be trained, in parallel, on complex object recognition tasks that typically take about a month or less. Using this system, we were also able to measure rats' perceived similarity judgements for stimuli to be used for subsequent neuronal recordings. 

\subsection{Optical imaging systems in awake, head-fixed rats}
Once we were able to demonstrate a slice of the robust visual capacities of rats, we next established a suite of tools for optical imaging in head-fixed rats. In Chapter 2, we described an optimized pipeline that enables a naive, wild-type laboratory rat to be suitable for cellular resolution imaging in visual cortex while it is awake and head-restrained. Moreover, our imaging system allows the same cells in a given FOV to be tracked across multiple days of recording. As yet another benefit provided by rodent models for vision, we also demonstrate the feasibility of imaging multiple visual areas at once, which has not been possible in awake rats yet. Our approach overcomes maybe challenges that have precluded the rat as a standard model for visual circuit study, despite being the most widely-used animal model across biomedical disciplines. 

\subsection{Basic characterizations of rat extrastriate cortex}
As the first demonstration of optical imaging in extrastriate regions of rat cortex, it was important to contribute baseline metrics of neural responses in these areas for the first time with our suite of new tools. Thus, in Chapter 3, we presented a systematic survey of visual response properties across areas V1, LM, and LI. We selected these areas due to their special place in the field of traditional visual neuroscience as one of the first non-primate species in which both behavioral and neurophysiological signatures of invariant object recognition has been found. Consistent with previous studies in both rats and mice, we found increasing receptive field sizes in extrastriate areas. Interestingly, we also observed several forms of anisotropy in the visual field representations of all areas measured. Cortical magnification was greater along elevation than azimuth, meaning that rat visual cortex contains expanded representations of the vertical dimension compared to the horizontal dimension. We also found that receptive fields were elongated along the horizontal axis, raising the possibility that these anistropic receptive fields facilitate a higher resolution representation of the vertical dimension. Finally, we also found asymmetries in retinotopic scatter: although scatter was greater along elevation for all visual areas, it was not proportional to the asymmetric cortical magnification in LM and LI, as it was in V1. Rather, scatter in elevation was lower than expected, suggesting higher fidelity representations in elevation. Together, these findings raise the possibility of an alternative mechanism for enhanced representations in a non-foveating animal. With the development of head-mounted, eye-tracking acquisition systems\cite{Meyer2020, Michaiel2020}, it is possible to explore these observations further in both mice and rats. 

In addition to biased visual field representations, we also found strong axis tuning and selectivity in V1, and consistent with previous studies in mice, there was an over-representation of cells preferring cardinal axes, especially for horizontally-oriented or vertically-moving gratings. Relative to primates, rodents likely experience different visual statistics, and the biases in edge motion and receptive fields could reflect non-uniform changes in the visual field as an animal runs around close to the ground. 

We also found greater direction tuning in LI than we might have expected from a purely higher-order area like monkey IT. Consistent with Vermaercke \textit{et al.} (2014), we found greater direction tuning in LI than in earlier visual areas, whereas there was comparatively lower axis tuning in LI. These results indicate that lateral extrastriate cortex may be more tuned to motion or moving stimuli than a standard ``primate-like'' object recognition pathway. Furthermore, higher shape discriminability, relative to V1, that was observed in both awake rats\cite{Vermaercke2014} and mice\cite{Froudarakis2020}, was measured using moving stimuli. It is possible that visual object recognition in rodents is closely tied to motion statistics --- given that animals navigate in complex, dynamic environments, studies in rats and mice raise the exciting possibility that traditionally separate ideas, such as the ``what'' and ``where'' pathways, might have closer ties than previously appreciated in the primate brain. 

To date, most studies have not found the same, clearly-defined separation between proposed ``layers'' of the rodent visual hierarchy. Although a growing body of evidence supports this idea, it is also likely that there are fundamental differences in how these visual systems are organized. 

\section{Comparison with existing methods}
Typically, rats are used in freely-moving or unrestrained paradigms. Electrophysiology is commonly used in rats, and in awake animals, provides a powerful preparation for studying neural activity in the context of complex and naturalistic behaviors, as the animal need not be restrained. However, chronic access to the same cells across long periods of time, such as over the course of learning, is challenging and difficult to verify. Furthermore, although increasingly higher-density probes may improve the resolution of recording, they can damage neural tissue, and fine-scale, cell-type-specific manipulations are much harder to control (as opposed to, say, holographic stimulation).  

For optical imaging, the larger size of the rat has been advantageous, as head-mounted scopes can be affixed to the skull for chronic, long-term imaging. However, there is usually tradeoff between having a small FOV with cellular resolution (head-mountable scope) or a large FOV without cellular resolution (single-photon). Moreover, in order to access lateral cortex on the side of the animal’s head, head-mounted preparations are difficult to maintain in a stable way. Scott et al., (2013) successfully demonstrated the feasibility of voluntary head-fixation for cellular resolution imaging in trained rats. However, this involves time-intensive and laborious training, and data acquisition is less under experimenter control. 

Our study overcomes many of these trade-offs and demonstrates the feasibility of high-resolution, large-FOV imaging with cellular resolution in awake, head-fixed rats. We leverage the head-fixed system to simultaneously track high-resolution video of the animal’s facial movements and behaviors. Although head-fixing the animal comes at the cost of studying neural activity under unnatural conditions, it comes with the benefit of minimizing highly complex behaviors and actions that are irrelevant to the stimuli being investigated. Specifically, this integrated approach allows us to investigate visual object representations in the context of different states of arousal. Typically, animals are not engaged in a fixed position, let alone a fixed behavior state, when interacting with objects in the world. As such, it is important to understand how different behavior states and task conditions modulate the extent to which neural representations can or cannot support complex behavior such as invariant object recognition.


\section{Comparison with previous studies in rodents}
Vermaerke et al. (2014) used electrophysiology to record from awake, head-fixed, naive rats, similar to our study. They found that linear decoding accuracy for static images (simple shapes presented at a given position) were best in V1, while LM and LI accuracies were barely above chance. In contrast, matching for the same pseudo-population sizes (N=64 cells), we found discriminability to be comparable across all areas under study (V1, LM, and LI) and well above chance. This could be due to differences in stimuli, as they use simple stimuli composed of oriented edges (e.g., triangles, squares), while we use slightly more complex, pseudo-3D object stimuli.

Tafazoli et al. (2017) also recorded in naive rats with electrophysiology, but used stimuli similar to ours and recorded in anesthetized, head-fixed rats. Overall, they found significant improvements in all metrics tested for area LL, which was not included in our study. However, their findings in areas V1, LM, and LI are consistent with our results. They found that across areas V1, LM and LI, classifier accuracies on tests for linear separability and generalization were comparable, though LI performance was significantly greater than that of V1 and LM. This is consistent with our finding that, of the three areas, LI appears the most robust to generalization tests across size.

Interestingly, they also found that LM accuracies were the worst overall, ~5-8\% lower classifier accuracy than V1 and LI. We find a similar pattern of results, with LM accuracy ~8\% lower than V1 and LI) when matching for pseudo-population size (n=96 cells), as does Vermaerke et al. (2014), with LM performing the worst in discriminating static images. Absolute accuracy levels were higher in our study and Vermaerke et al., compared to accuracy levels reported for a subset of conditions by Tafazoli et al. (pseudo-population, n=96 cells). This could be due to differences in behavioral state (Tafazoli et al. recorded in anesthetized rats) or differences in stimuli (Tafazoli et al average across a much more diverse and complex array of object images). 

\section{Comparison with other species}
Froudarakis et al. (2020) is the only study to show that mice may be capable of the type of object recognition tasks used to train rats. Although overall performance in mice falls short of the accuracy levels we find in our trained rats, generalization appears robust. Their study provides a valuable point of comparison as they also record in awake, passively-viewing animals using two-photon imaging.

Unlike most rat studies, Froudarakis used dynamic movie stimuli as opposed to static images while recording in awake, head-fixed mice. Like Vermaerke et al., who also used dynamic movie stimuli, Froudarakis et al. found that discriminability increases from V1 to LM to LI at the level of single neurons -- these single unit results are similar to those of Vermaerke et al. (2014), who found increasing discriminability by another metric of shape selectivity, i.e., sparseness. However, at the population level, the ephys rat studies and imaging mouse study appear to differ, with highest discriminability in LM in the mouse (and area AL, not tested here), and in rats, the worst performance across all metrics for area LM. Froudarakis et al. also find an increase in discriminability as a function of stimulus size. These results are consistent with ours, but only for areas V1 and LM. In area LI, we find that discriminability, as measured by classifier accuracy, is fairly constant across the range of sizes tested. 

Both Froudarakis et al. and Tafazoli et al. tested multiple types of identity-preserving transformations, and consistent with our results, that LI appears more robust to size transformations, both studies find that LI tends to exhibit some improvement beyond V1, depending on the particular transformation. Interestingly, Froudarakis et al. find LM and AL to be the most robust to transformations, whereas this is area LL for Tafazoli et al. Area LL is a region lateral to LI in rats, but not tested in Froudarakis et al, so future studies may help identify additional extrastriate areas that exhibit features thought to be important for visual object recognition.  

\section{Caveats}
Though the present study presented with many technical difficulties, one consistent challenge was consistent identification of area LL. Area LL is notable because previous studies measured electrophysiological responses , There are several possibilities, which we address now. For example, using many injections of viral GCaMP to cover the cranial window proved to be much more time-consuming and less efficient than desired. Patches in 

Compared to previous studies of tolerant object representations in rodent visual cortex, our study presents a limited set of shapes and transformations. As such, it is difficult to identify the extent to which our results are generalizable across different types of transformations. Given that previous studies have shown that there are asymmetries across transformations in separability and generalization, future work can investigate the extent to which there are interactions in the types of tolerant representations a given visual area can support. For example, given that arousal modulates gain and tuning of simple feature detectors like V1 cells, it would be interesting to investigate how arousal modulations of simple features propagates to downstream, high-level representations.

Although we imaged in awake, head-fixed rats, our recordings were in naive, passively viewing animals. Since vision is less of a dominant sensory modality in rodents than it is in monkeys, presenting visual stimuli that have acquired behavioral importance through training may result in significant differences than has been shown in previous object recognition studies in rodents thus far. However, since many of the studies characterizing the hierarchical organization of primate visual cortex have relied on naive monkeys, either passively viewing or engaged in a simple, orthogonal task. As such, recording in naive rodents allows a valuable point of comparison between the species, as they likely experience dramatically different visual statistics during development.


\section{Future Directions}
Currently, mice are one of the most commonly used models in studies that leverage the power of cellular resolution imaging with genetic tools in awake animals. Although rats are an equally popular model system across many fields of neuroscience, such techniques have remained challenging to apply to larger rodent models. Future studies may leverage the developments and findings of the present study to combine training behavior with two-photon imaging. Many of the existing genetic tools used in mice are readily applicable to rats, and other rodents such as transgenic rats that express GCaMP pan-neuronally or in cell-type specific populations. Combined with multi-channel systems, as presented here, fine-scale circuit dissection and manipulation is readily available for future studies in rats. 

One of the most exciting avenues in systems neuroscience research today is the ability to study neural circuits simultaneously with behavior over the course of learning. Despite rats being the standard model for studies of learning and memory, few studies have been able to track the same cells over time in rats learning these complex tasks. Over a decade ago, Zoccolan et al. (2009) demonstrated that rats are capable of invariant object recognition, a behavior that was long considered to be unique to primates. Ten years later, Froudarakis et al have shown that mice, too, are capable of this complex visual behavior. Although a great deal has been learned about how a biological system solves this problem, many questions remain that are unfeasible to ask in primates, and rodent models offer a promising alternative by which both general principles and species-specific adaptations can be discovered. 

Over the past decade, a growing number of studies have started to parse out possible functional hierarchies within rodent visual cortex. At present, it remains unclear whether rodent visual areas neatly map onto primate visual areas. In the context of visual object recognition, rodent visual cortex seems less starkly differentiated, although broad principles, such as increasing view tolerance and object discriminability are beginning to emerge. However, investigations into rodents as a model for what is traditionally considered ``high-level'' vision have only just begun. Our study closes a long-standing gap to unlock the rat as a powerful model system for systems neuroscience. 

The technological advancements presented in this work have the potential to unlock a wide range of new experimental directions, enabled by the superior molecular and genetic tools available in rodents. With the groundwork laid out in the previous chapters, we overcome significant barriers to position future studies to ask new, fundamental questions about the nature of visual population representations in cortex, how they change with experience, and how they might be read-out by downstream cortical areas. By approaching these questions with a technique that allows the measurement of responses from a large population of neurons tracked across days, weeks, and months, it is possible to ask new questions about the nature of population representations in cortex that have been inaccessible for decades. 

This work sits at the vanguard of a growing trend of using rodent models to address questions more traditionally explored in non-human primates.  The cognitive capabilities of rodents have been consistently underestimated, but increasingly, research groups have successfully challenged the notion that high level processes (such as decision making) can only be studied in primates. This project opens the way for future studies to ask new, fundamental questions about cortex that were previously inaccessible using other experimental means. 