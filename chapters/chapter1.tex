% \begin{savequote}[75mm]
% Does this shit even work?
% \qauthor{A Tired Grad Student}
% \end{savequote}

\chapter{High-throughput behavior in rats}
\newthought{The laboratory rat \textit{Rattus norvegicus}} was the first mammalian species domesticated for scientific research\cite{Jacob1999}, and has since been the most widely studied species in biomedical research. In the lab, rats can be trained to perform cognitively demanding tasks. They have a long history as laboratory models for the behavioral study of cognitive capacities, including decision-making\cite{Raposo2012, Miller2017TwoStep, Piet2018, Brunton2013}, working memory\cite{Bratch2016, Fassihi2014, Akrami2018} , and spatial navigation\cite{OKeefe1971, Whishaw1995, Aronov2014}. 

One of the most widely used tools for studying animal behavior in the lab is the operant conditioning chamber. With the conditioning chamber, the experimenter gradually shapes the animal's behavior until the desired task is learned. Most rodent behavior experiments, including studies of visual object recognition, rely on operant conditioning. Technological developments over the past ten years have enabled experiments to use these traditional conditioning boxes in computer-controlled systems that allow for automated and high-throughput training. 

Automated training methods are more efficient as they require little to no hands-on involvement from the experimenter. Animals can be placed into chambers by staff who may be less biased about the particular study's goals or they can simply live in the boxes with automatically or remotely controlled training regimes\cite{Qiao2018, Miller2017TwoStep, Poddar2013}. Thus, high-throughput systems not only allow for more systematic and less biased experiments, but also allow many animals to be trained and studied in parallel. Higher-throughput studies provide statistical power difficult to achieve with small-scale animal cohorts and importantly, have the potential to provide a readily available source of animals for physiological access or perturbation studies. These advantages are particularly important for behavioral tasks that are complex and require long training schedules.

Several groups have demonstrated the power of high-throughput training systems for the study of cognitive behaviors in rats. Of note, Brody and colleagues use highly complex tasks that take rats anywhere from 1 month to 4-6 months to learn\cite{Brunton2013, Miller2017TwoStep, Constantinople2019} and have developed high-throughput, automated training systems that train many rats in parallel (20 to 30+ rats\cite{Brunton2013, Constantinople2019} on various decision-making and working memory tasks\cite{Miller2017TwoStep, Brunton2013}. In motor skill learning, {\"O}lveczky and colleagues have built high-throughput, fully-automated systems for home-cage training, which allows similar ranges of animals to be trained in parallel on the same or different variants of a motor skill-learning task\cite{Poddar2013}. 

In the context of visual behaviors, rats have been studied for their capacity to discriminate shapes for a long time. In 1930, Karl Lashley\cite{Lashley1930} described a wide range of visual behaviors in rats using what is now a classic two-choice paradigm. Lashley trained rats to select one of two visual stimuli in order to access a hidden door behind which there was a food reward\cite{Lashley1938}. Prusky utilized rats' swimming abilities to measure their visual acuity, and even compared rats and mice, finding that rats had superior visual acuity than mice\cite{Prusky2000}. Over the last ten years, a growing number of studies have demonstrated rats' ability to perform tasks of invariant or tolerant object recognition using a similar two-choice paradigm as Lashley's hidden doors and Prusky's two-arm water maze\cite{Zoccolan2009, Vermaercke2012, Tafazoli2012, Alemi-Neissi2013, Djurdjevic2018}. While most studies using monkeys rely on about 2-3 animals, standard rat vision studies have used $~$4-6 animals per experiment. Inspired by the work of Brody, {\"O}lveczky, and others, our goal was to take existing visual behavior paradigms in rats and adapt them for high-throughput, automated training. 


% This is a math equation that can go here for now.
% $$\zeta = \frac{1039}{\pi}$$

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Results
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% fig:openratbox
% fig:basic_training
% fig:behavior_generalization

% ---------------------------------------------------------
% OpenRatBox -- the hardware.
\section{OpenRatBox: An open-source platform for high-throughput visual behavior experiments in rats}
Our approach was to design a system that was reproducible, low-cost, and modular. It was critical to design training boxes that would be straightforward to reproduce, not only to maintain constancy from one box to the next, but also to facilitate widespread use both within the lab and across labs. Systematization across research groups can be immensely powerful, especially for studying highly complex, multi-modal processes like decision-making, as exemplified by the International Brain Laboratory and the Allen Brain Institute.

In order to build behavior boxes at a larger scale, we relied on low-cost, readily accessible components and open-source software for experimental control. While it is possible to build a highly sophisticated and customized apparatus that meets the particular demands of a given experiment, it can be extremely costly and hard to adapt for other experiments or impossible to use by other labs. In contrast, designing a low-cost system that relies on open-source technology allows it to be more accessible as a tool that can benefit others, while also allowing for continued improvements and new adaptations. Modularity is important because a given behavior can be tested under different regimes. For example, two commonly used behavior choice paradigms are Go/No-Go and two-alternative forced choice (2AFC) tasks. These paradigms offer different advantages and disadvantages, and also have different hardware requirements: while Go/No-Go paradigms only require a single reward port or choice manipulandum, 2AFC and other multi-choice tasks require at least two. 

% FIGURE 1.1 OpenRatBox Schematic
\begin{figure}[t!]
    \includegraphics[width=\textwidth]{figures/chapter_1/fig_1-1_openratbox/fig_1-1_openratbox_compressed.pdf}
    \vspace{.1in}
    \caption[OpenRatBox]{OpenRatBox: Open-source, automated, high-throughput training. \textbf{A.} Schematic of one training box. Numbers denote relevant parts. 
    \textbf{B.} Left, A full tower assembly of four identical training boxes. \textbf{C.} A photograph of a rat in a training box equipped for a three-port task. \textbf{D.} A photograph of a room of towers used to train the animals in the present work. An experimenter is shown loading an animal in its home cage into the training box.  
    \label{fig:openratbox}}
\end{figure}

The overall design of each box is identical, and experiment-specific adjustments are made with modular components. The main vestibule of each unit houses the animal's cage and all hardware needed to collect the animal's response and monitor its behaviors (Figure\ref{fig:openratbox}A). Each unit is equipped with a small computer that allows as many experiments to be run independently and in parallel as there are boxes. The external frame is composed of aluminum extrusion bars and custom-cut acrylic paneling that fits into the railing slots of the bars, such that an arbitrary number of boxes can be built on top of the next, limited by the available vertical space. In our behavior rooms, we had enough space for towers composed of 4 stacked units (Figure\ref{fig:openratbox}B). All the training boxes are controlled and monitored by a control computer that runs a client (MWorks) that interfaces with the servers running in each behavior box. 

Within a given unit, there are two partitions. The monitor is mounted on a partition separate from the main vestibule in order to keep it clean and protected (for example, from chewing, or stray water droplets and bedding). The animal has visual access to the monitor through a window separating the monitor from the main vestibule that holds the cage. The cage itself is held in place with two spring-loaded latches that allow the cage to be loaded into the same relative position, if necessary. The cage locking mechanism was adapted from a commercially available, self-standing animal cage rack, in which each cage is locked into the air circulation and filtration system. The box is thus designed to support fully live-in animal behavior training. 

During visual behavior sessions, the animal has access to the reward ports and monitor through a small window placed at one end of the home cage. In the case of live-in training, the window can be gated shut during non-training times, if desired. Mini extrusion bars are screwed directly into the acrylic floor of the main vestibule around the animal's access window. This effectively creates a mountable rail system for attaching experiment-specific components, such as reward ports, USB cameras, and IR detectors (Figure\ref{fig:openratbox}A). As such, any modifications specific to a paradigm (\textit{e.g.}, one reward port or three reward ports, see example in Figure\ref{fig:openratbox}C) could be easily attached or removed from one box to the next. All wiring feeds through small access holes cut into the acrylic pieces embedded into the extrusion bars, as does tubing for water delivery of rewards. Attached to each box is a small computer (Mac Mini, though others are possible) that runs the experiment (visual stimulation, I/O control, and so on). 

In addition to specific behavior task constraints, such as 1 reward port or multiple, a desirable feature of behavior systems is the ability to combine them with physiology or neural manipulations. The behavior rigs are modular enough that rats with tethered cables can also be housed in the boxes, as there is sufficient room for an access port and a commutator that can hold the cabling attached to the animal's head. Thus, the entire system can be equipped for neural stimulation and recording in tethered rats. The spacing between the stacked boxes can be kept as is or adjusted for a commutator system that carries a cable from the animal's head through a hole in the acrylic ceiling of the main vestibule (Figure\ref{fig:openratbox}D). Though we tested both Go/No-Go and two-choice behavior paradigms, we selected the latter for the remainder of our behavior studies as this is a well-established paradigm used to test visual object recognition behavior in rats\cite{Lashley1930, Zoccolan2009, Prusky2000}.

% ---------------------------------------------------------
% OpenRatBox -- the functionality (high-throughput training)
\section{High-throughput behavior training}
We first trained rats to perform a simple, two-category object discrimination task\cite{Zoccolan2009} (Figure\ref{fig:basic_training}A). This is a two-choice task in which the rat navigates between three access ports to start trials and provide responses. Specifically, the rat licks a center port to initiate a trial, which triggers an image to appear on computer monitor. The rat indicates which object the image corresponds to be licking one of the two flanking ports, \textit{e.g.}, the left port, for object A, and the other \textit{e.g.}, for object B (Figure\ref{fig:basic_training}B).

% FIGURE 1.1 Basic training
\begin{figure}[t!]
    \includegraphics[width=\textwidth]{figures/chapter_1/fig_1-2_basic_training/fig_1-2_basic_training.pdf}
    \vspace{.1in}
    \caption[High-throughput training]{High-throughput training on a simple two-alternative choice task. 
    \textbf{A.} Logic of the basic, two-category object discrimination task. 
    \textbf{B.} Trial structure (adapted from \cite{Zoccolan2009}). Rats initiate a trial by licking the center port. After a variable delay, an image appears on the screen. The animal licks the left or right port to indicate it sees object A or object B (or vice versa). Correct responses result in water rewards, while incorrect responses result in negative feedback (see Methods). 
    \textbf{C.} Example training data for one rat. Black, overall accuracy by training session. Gray, number of trials completed in each session. 
    \textbf{D.} Accuracy in \textbf{C} split by object identity. Colors correspond to each of the two object identities.
    \textbf{E.} Training accuracy by session number for a large cohort of animals (N=33 rats). 
    \textbf{F.} \textit{Top}: Accuracy for each box and tower. 4 boxes were vertically stacked to create 1 tower, 4 towers are shown (indicated by gray boxes below the plots, tower-1, tower-2, \textit{etc.}). The relative position of each group within the tower represents the same physical location in each tower (top, second from the top, \textit{etc.}). \textit{Bottom}: Number of trials performed per session in each box and tower during training. Each dot denotes a session for an animal. Organization of grouped points is the same as the upper panel (corresponding to boxes and towers). 
    \textbf{G.} Performance split by stimulus-port mapping and object identity. Red, accuracy for object A. Blue, accuracy for object B. Port numbers 1 and 2 denote whether the animal is assigned to lick port 1 for object A or port 2 for object A, and vice versa.
    \label{fig:basic_training}}
\end{figure}

Animals could be trained to perform shape discriminations in one month or less, and readily performed several hundreds of trials per day in the automated training rig (Figure\ref{fig:basic_training}C-F). Importantly, overall behavior metrics were similar across all behavior box units and towers. We observed no differences in overall accuracy, accuracy by port assignment, or number of trials completed per session (Figure\ref{fig:basic_training}F-G). Almost all rats reached criterion for the appropriate stimulus-port pairing in about 2 weeks (Figure\ref{fig:basic_training}). Trained rats performed with high accuracy for both objects (n=REFREF/33 rats reached criterion performance of 70\% correct across 20+/-3 sessions). These results demonstrate that our behavior units are reproducible and successful for training large cohorts of animals. 

% ---------------------------------------------------------
% Behavior Generalization
\section{Visual object recognition behavior}
Previous studies have demonstrated that rats are capable of recognizing never-before-seen views of familiar objects\cite{Zoccolan2009, Vermaercke2012, Tafazoli2012}. Our goal was to validate that rats will perform these behaviors in our high-throughput system. Using OpenRatBox, we tested how rats generalize across two types of transformations: the first was a perceptual similarity test of the complex objects, by which we identified rats’ discrimination thresholds separating one object from another, and the second was an invariant recognition test, where rats had to discriminate objects across changes in particular views (Figure\ref{fig:behavior_generalization}A). 

Only rats that reliably discriminated between the two original objects (criterion, 70\% accuracy) continued to the generalization tests. To identify perceptual discrimination thresholds separating the two objects, we tested identity-changing transformations in which images were parametrically varied between the two original objects at a given view. Specifically, we created a shape continuum by generating a series of morphs that varied along a high-dimensional identity axis separating the two original objects (as shown in Figure\ref{fig:behavior_generalization}B). The identity axis was defined in N-dimensional pixel space, and morphs were selected to evenly sample distances along this axis (see Methods). We then tested the extent to which linear similarity in pixel space reflected perceived similarity in rats trained to discriminate the two anchor objects. 

% FIGURE 1.3 Behavior generalization.
\begin{figure}[t!]
\includegraphics[width=\textwidth]{figures/chapter_1/fig_1-3_behavior_generalization/fig_1-3_behavior_generalization.pdf}
    \vspace{.1in}
    \caption[Generalization of visual behavior]{Generalization to identity-preserving and identity-changing transformations. 
    \textbf{A.} Training and testing pipeline. Animals are first trained on the basic discrimination task. Those that pass criterion performance are then tested on identity-changing or identity-preserving generalizations on probe trials that are interleaved with the basic task. 
    \textbf{B.} Morph stimuli create an axis along which identity changes across a stimulus continuum between the original anchors, object A and B. 
    \textbf{C.} Example data on the morph probe trials for one rat. Dots, average across trials for each morph level. Line, fit psychometric curve. 
    \textbf{D.} Psychometric curves for one cohort (N=10 rats). Thin lines, individual rats. Thick line, average psychometric curve across rats. 
    \textbf{E.} Identity-preserving transformations tested for each of the original objects: 6 sizes and 9 in-depth rotations. Green, subset of conditions used for training. Green, test transformations for which feedback was never provided. Purple, size-matched, \textit{i.e.}, acuity-matched, transformations of the test views, but for which feedback was provided, to compare the effect of feedback on generalization performance. No-feedback quadrants were counterbalanced across animals. 
    \textbf{F.} Performance for all identity-preserving transformations for each object for an example rat. Colors and stimulus conditions are ordered as in \textbf{E}. \textbf{G.} Accuracy for rats in one cohort (n=10 rats) for train views, test views, and size-matched feedback views. Colors as in \textbf{E}. Each circle denotes session accuracies for a given rat, all rats shown. Error bars, SD.
    \textbf{H.} Accuracy as a function of the Nth presentation of a given transformation for feedback-provided (purple) and no-feedback (green) conditions. Shading, SD across animals. Dashed line, 50\% accuracy, or chance performance.
    \textbf{I.} Accuracy for each depth-rotation tested. Each dot is the session accuracy for a given rat. Horizontal and vertical bars, mean and SD across sessions. Dashed line, chance performance.
    \textbf{J.} Same as \textbf{I}, but for each stimulus size tested. Conventions as in \textbf{I}.
    \label{fig:behavior_generalization}}
\end{figure}
%     \caption*{\textbf{Figure 2.1} Example figure and tips -- A) Your figure numbers should follow the format of Figure chapter#.figure#. B) Set width equal to textwidth. C) Specify position as [t!] to insert at page top.}
% \end{figure}

Rats were presented with a morph image on a small fraction of trials (<15\%, see Methods) during the ordinary discrimination task. No feedback was provided on these probe trials in order to measure perceived, rather than trained, perceptual judgements. These probe trials were then used to build up a psychophysical curve to determine the animals' naive behavior in classifying the objects as ``A'' or ``B''. We fit a psychometric curve to the probe trials using maximum likelihood estimation (see Methods). These curves characterize the category boundary along the morph axis (Figure\ref{fig:behavior_generalization}B). We found that that rats perceptual choices matched the physical similarity of the morphed objects, though there was individual variation across rats (Figure\ref{fig:behavior_generalization}C-D). 

% FIGURE 1.3 INVARIANCE TEST
To test how well animals discriminate objects across shape changes that preserve object identity, we tested the same rats on an object recognition task. Consistent with previous studies\cite{Zoccolan2009, Tafazoli2012}, we found that performance generalized robustly across identity-preserving transformations, such as changes in size and in-depth rotation (Figure\ref{fig:behavior_generalization}E-F). Importantly, accuracy was high on test trials (~80\% accuracy), where animals never received feedback (Figure\ref{fig:behavior_generalization}F-G), demonstrating that performance on novel views was spontaneous, rather than learned. In fact, accuracy was high across all presentations of novel views, with or without feedback (Figure\ref{fig:behavior_generalization}H). Although there was variability across animals in accuracy for each of the transformation axes of rotation and size (Figure\ref{fig:behavior_generalization}I-J), all rats showed high accuracy across all views. The only exception in the results presented here was low accuracies for the smallest stimulus sizes (Figure\ref{fig:behavior_generalization}J). However, when we tested a separate cohort of animals (not shown) that were only presented with the smallest stimulus sizes, rats showed high levels of performance, suggesting this is a strategy effect, rather than a reflection of rats' inability to perform the task. These results demonstrate that rats are capable of true generalization, and are not simply learning stimulus-response pairings. 

% ---------------------------------------------------------
% Closing remarks
\section{Concluding Remarks}
In summary, we describe a high-throughput behavior system, OpenRatBox, that robustly and reliably trains large cohorts of rats to perform visual tasks (Figure\ref{fig:openratbox}). We found that rats readily perform hundreds of trials per day, and training is consistent across all replications of the training box, demonstrating that the training unit is both reliable and reproducible (Figure\ref{fig:basic_training}). We also show that with OpenRatbox, we are able to replicate previous findings demonstrating that rats robustly generalize to novel views of objects. Specifically, we tested rats' ability to generalize performance across identity-preserving transformations, and to make perceptual choices that follow our morph axis of identity transformations (Figure\ref{fig:behavior_generalization}). Although similar behavioral results have been shown previously\cite{Zoccolan2009, Tafazoli2012, Vermaercke2012}, our results demonstrate that a) we can replicate these results with our high-throughput behavior system, and b) in response to our particular stimuli, rats respond correctly in the absence of training on the transformations (no feedback conditions and morph probe trials). We will use the same stimuli when characterizing neural representations in naive rats in Chapter 4. 

A major goal of this collection of studies is to establish a robust pipeline for high-throughput behavior and cellular resolution imaging in awake rats. Due to the difficulty of the visual behaviors under study (object recognition), and the inevitable attrition of rats when physiology is added to such studies, a behavior system that outputs trained animals in large numbers with minimal experimenter intervention is highly valuable. In contrast to previous object recognition studies, we demonstrate a capacity to train animals on these visual tasks at the level of existing high-throughput paradigms in rats (>30 rats).  

Several additional features designed into OpenRatBox promise to provide broader benefits to the community of researchers studying rat behavior. First, the training box is modular, allowing multiple reward port configurations, as well as combination with neural recording and manipulation. Specifically, both single-port (Go/No Go) and multi-port (2AFC) tasks can be tested by swapping out the port array screwed into the micro-frame in front of the animal's cage. For neural recording and/or stimulation, a hole cut into the top panel of the training box allowed wiring to connect from a headstage affixed to the animal's head to a commutator mounted just outside the box to offset the weight carried by the animal and prevent the tether from tangling. Second, the training system is low-cost, relying on relatively inexpensive components and open-source software (Arduino, MWorks, OpenEphys). All the custom-cut paneling and parts are also available in a publicly accessible repository (see Supplemental Materials), allowing either the exact same system to be built or custom modifications for future experiments. 




% In Go/No-Go (GNG) paradigms, the animal responds to a given stimulus (the "Go" condition) by licking a choice port or pressing a lever, and must withhold a response otherwise (the "No-Go" condition). GNG paradigms have fewer moving parts, requiring only one response type, which can make it easier to learn. However, subjects tend to make more Go responses in the GNG task, as the Go response is rewarded while other other behaviors are not\cite{REFREF}. 

% For physiology experiments, GNG paradigms are more amenable to head-restrained animals, since the animal only needs to make one type of response. On the other hand, since reward strongly modulates neural activity, and GNG paradigms can be challenging as the stimulus, response, and reward are tightly linked\cite{REFREF}. Multi-port tasks, like two-choice paradigms, overcome many of these drawbacks, as the animal is trained to respond in one way to condition A and some other way to condition B. In this way, the stimulus, response, and reward can be disentangled, but at the cost of a more complicated task structure that can make interpretations difficult in still other ways. However, they can be more difficult to adapt for head-restrained conditions. Animals normally use head movements or their whole body to reach one reward port or the other\cite{REFREF}, which is not possible in physiology experiments that require the animal's head to be fixed in place in the recording apparatus. 


% \texttt{This is a line of code.}


% For an example of a full page figure, see Fig.~\ref{fig:myFullPageFigure}.

% % EXAMPLE FIGURE 
% \begin{figure}[t!]
%     \includegraphics[width=\textwidth]{figures/chapter_1/ratbox_schematic.pdf}
%     \vspace{.1in}
%     \caption*{\textbf{Figure 2.1} Example figure and tips -- A) Your figure numbers should follow the format of Figure chapter#.figure#. B) Set width equal to textwidth. C) Specify position as [t!] to insert at page top.}
% \end{figure}

%% Requires fltpage2 package
%%
% \begin{FPfigure}
% \includegraphics[width=\textwidth]{figures/fullpage}
% \caption[Short figure name.]{This is a full page figure using the FPfigure command. It takes up the whole page and the caption appears on the preceding page. Its useful for large figures. Harvard's rules about full page figures are tricky, but you don't have to worry about it because we took care of it for you. For example, the full figure is supposed to have a title in the same style as the caption but without the actual caption. The caption is supposed to appear alone on the preceding page with no other text. You do't have to worry about any of that. We have modified the fltpage package to make it work. This is a lengthy caption and it clearly would not fit on the same page as the figure. Note that you should only use the FPfigure command in instances where the figure really is too large. If the figure is small enough to fit by the caption than it does not produce the desired effect. Good luck with your thesis. I have to keep writing this to make the caption really long. LaTex is a lot of fun. You will enjoy working with it. Good luck on your post doctoral life! I am looking forward to mine. \label{fig:myFullPageFigure}}
% \end{FPfigure}
% \afterpage{\clearpage}

