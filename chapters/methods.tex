\chapter{Methods}
\label{methods}


% Materials and methods
All experimental procedures were reviewed and approved by the Harvard Institutional Animal Care and Use Committee. Experiments were performed at Harvard University. 
Animals
Animals used in this study were female Long-Evans rats, 3 months or older, weighing 250-350g (Charles River Laboratories). Rats were housed on a ventilated rack under a 12 hour light:dark cycle with food and water ad libitum, except when water-restricted for behavior training. 

\section{Surgery}
\subsection{Viral injections}
Intracortical injections were made at multiple sites (~5-15 sites per cranial window, spaced ~0.5-1mm apart) using a microinjector (NanoFil, World Precision Instruments REFREF) fit with a 36G beveled needle (NF36BV-2, WPI). A total of 500-750 nl was injected per site at a constant rate of 10-25nl/min at a depth of 750 um below the surface. A high-titre (TITRE) solution of viral vector (AAV9-syn-jGCAMP7f-WPRE, Addgene) was diluted to a final ratio of 2:1 with a 20\% mannitol solution (Sigma-Aldrich, part # REFREF) to promote diffusion. Trace amounts of Fast-Green (Sigma-Aldrich, part #REFREF) were added for visual confirmation of injected solution in the brain.

\subsection{Headplate implantation}
Aseptic surgical technique was followed during all survival surgeries. A headplate and cranial window were implanted in the same surgery as viral injections using methods modified from mouse cranial window procedures \cite{Goldey2014}. Rats were administered dexamethasone (2 mg/kg, REFREF) ~3 hours prior to surgery in order to reduce brain swelling. Rats were anesthetized using isofluorane in 100\% O2 (induction, 3-5\%; maintenance, 1.5-2\%), and placed in a stereotaxic apparatus (Knopf Instruments, Angle Two, Leica REFREF). Eyes were protected from drying out ophthalmic ointment (Puralube), and then covered with surgical drape to protect from direct light. Heart rate, breathing rate, oxygen saturation, and body temperature were measured with a pulse oximeter and commercially available software (PulseOx, Mouseox). Body temperature was maintained at 38%\circ%C with a feedback-controlled heating pad (REFREF). 

The head was shaved, followed by an application of Nair (REFREF) to clear the site of any hair around the incision site. The exposed scalp was cleaned with saline (REFREF), then wiped with three rounds of Povidone-Iodine swabs (Medline, REFREF). A small lidocaine block (<0.5 cc REFREF) was administered along the incision site, which spanned from just behind the ears to the back of the head. After the incision, the skull surface was thoroughly cleaned with hydrogen peroxide (Swan REFREF) and a mixture of citric acid (10\%) and ferric chloride (3\%) (Parkell #S393). A series of small indentations were placed using a small drill (REFREF) all across the cleaned skull to increase surface area and texturize the skull in preparation for adhesives. Prior to head plate attachment, the center of the craniotomy was marked at -7.0 to -8.5 mm AP, 4.5 to 6.5 mm ML, depending on the areas being targeted for each animal. The implant procedure did not require any bone screws or additional supplements to keep the implant stable across months. 

A custom titanium head plate was attached to the skull over the right hemisphere using dental glue (C&B Metabond, Parkell S380). The head plate was placed at 40 degrees relative to Bregma, which matched the orientation of the imaging plane and captured most of the targeted areas of visual cortex. 

\subsection{Cranial window}
After the head plate was securely glued to the skull surface, the wound margin was closed up, while leaving the circular region surrounding the craniotomy site exposed. A 4-5mm craniotomy was performed at the marked site by careful thinning of the bone with a dental drill within the circular area (Aseptico). Care was taken throughout the drilling process to keep the thinned region within the circular boundaries using a pair of surgical calipers (F.S.T. REFREF). Skull thinning was complete once the entire circular region was semi-transparent and blood vessels were clearly visible through the thinned skull. Once the skull was thinned down, the region was kept immersed in sterile saline (REFREF) for the remainder of the surgery. The remaining thinned bone was removed with laminectomy forceps (Fine Science Tools REFREF #). The dura was cut open using a bent 36G needle tip (REFREF) to gently lift up the dura enough to create a small incision point. Flaps of dura were then peeled back with fine forceps or spring scissors to expose the brain surface, and tucked away around the edges of the craniotomy. Intracortical injections were performed after the duratomy (see Viral Injections).

A window composed of stacked glass coverslips (4x4mm, 1x5mm, Warner Instruments, REFREF) bound with optical adhesive (Norland #71) was then placed over the brain surface. The remaining saline was partially absorbed out with sterile eye-spears (REFREF), and the craniotomy was sealed with cyanoacrylate glue (Vetbond, 3M) over a thin layer of sterile saline. Post-operative animals were administered buprenorphine (X mg/kg, REFREF) and carpofen (5 mg/kg, REFREF) daily for 5-7 days following the surgery.

\section{Widefield mapping}
\subsection{Animal preparation}
About 20 minutes prior to the mapping session, animals were anesthetized with isofluorane (5\% induction, 1-1.5\% maintenance) and administered a subcutaneous dose of cholorprothixene (2 mg/kg, Sigma-Aldrich). During the mapping session, animals were kept anesthetized with minimal levels of isofluorane (0.5-1\%). Anesthesia levels were maintained by testing the paw-pinch reflex and monitoring the breathing rate. The left eye facing the monitor was checked between trials to ensure it remained open and stable.

Multi-site viral injections allowed for greater coverage of exposed cortex, but resulted in patchy expression levels in a subset of animals. Animals with ambiguous retinotopic maps were excluded from further study (see AppendixSUP REFREF \ref{suppfig}).

\subsection{Tandem-lens macroscope}
Widefield mapping was done with a tiltable, tandem-lens macroscope\cite{Ratzlaff1991, Kalatsky2003}, composed of a USB 3.0 CCD camera (MantaG033-B, Allied Vision, REFREF) and 2 Nikon lenses (Nikon, 105-mm and 55-mm). Images were acquired at 25 Hz with 3x3 pixel binning (256x492 pixel ½-type sensor REFREF). Epifluorescence illumination was achieved with a 470nm LED (Thorlabs) that was filtered and reflected through a filter cube that housed an excitation filter (REFREF), dichroic mirror (Thorlabs, #REFREF), and emission filter (REFREF). 

Green fluorescence or reflected light was collected and passed through the filter cube then focused on a CCD detector (CAMERA REFREF). Images were acquired at REFREF Hz with REFREF spatial binning using REFREF CAMAPI software and custom python scripts (GIT REFREF). 
% Compare w. Wekselblatt et al. 2016:  Camera lenses allow a relatively high numerical aperture (NA) for light collection, which can also be adjusted easily using the f-stop setting to restrict the NA. This permits a flexible trade-off between sensitivity and depth of field, especially as increased depth of field is useful, given the curvature of the cortical surface. Imaging was generally performed at an f-stop of 5.6. The ratio of the focal lengths of the two lenses determines image magnification. To map 1 cm of cortex across the 2-cm detector (6.5 μm pixels), we chose 50 mm and 105 mm lenses, yielding magnification of 2.1× and 3.1 μm specimen pixels. In practice, we find an effective spatial resolution of ∼25 μm, based on the highest spatial frequencies present in nonbinned images of vascular structure. Binning across spatially oversampled pixels can reduce shot noise by allowing more total photons to be detected with increased illumination or NA. This is a standard practice in intrinsic signal imaging (Kalatsky and Stryker 2003) and is generally applicable at high light levels, where readout noise is negligible compared with photon count noise.

For epifluorescence illumination, we used a 470 nm LED filtered and reflected by a long-pass dichroic mirror, and emitted fluorescence was filtered and captured at an imaging rate of 25Hz. 


\subsection{Visual stimulation}
Visual stimuli were presented using custom Python scripts (git link REFREF) on a 72 inch LCD monitor (LG REFREF). The monitor was centered in front of the left eye, spanning 177 degrees of visual field along azimuth, 67 degrees along elevation.

The mapping protocol consisted of a periodic, moving bar stimulus \cite{Kalatsky2003, Marshel2011} presented to the (left) eye contralateral to the cranial window. The bar subtended 5 degrees of visual angle, and was either presented as a white bar drifting over a black background or an apertured bar containing one of 32 possible natural scene images drifting over a gray background (REFREF). The bar was presented at 0.13 Hz along the azimuth and elevation axes, for a total of 2 (downward, rightward) or 4 (downward, rightward, leftward, upward) conditions. A total of 4-5 repetitions of 10 cycles each were acquired for each direction. 

\subsection{Area segementation}
Raw fluorescence signals were corrected for slow drift by removing the rolling average of each pixel’s time course. The width of the rolling window was set to 2.5 times the length of the stimulation period. For each pixel, the time courses for each trial (10 cycles of the stimulus) were aligned and averaged for each condition (1 of 4 possible directions). We then performed a Fourier spectral analysis on the averaged time series for each pixel to get a magnitude and phase value for each pixel at each frequency. The strength of the response to the stimulus was calculated as the ratio of the Fourier magnitude at the frequency of stimulation to the sum of the magnitudes at all other frequencies \cite{Kalatsky2003, OTHERS}.

Retinotopic maps were created by taking the phase values for all pixels in the image and converting them to Cartesian coordinates that matched the linear position of the bar on the monitor to the phase of the stimulus cycle that corresponded to that position. All maps were smoothed with a Gaussian window (FWHM=$50um$) and masked by applying a threshold to the magnitude ratio.  

\section{Two-photon calcium imaging}

\subsection{Area identification and validation}
We targeted a given two-photon FOV by coregistering blood vessel images to widefield retinotopic maps, which allowed coarse-grained targeting of two-photon sessions. All two-photon imaging sessions began with an anatomical run, in which we acquired a surface level z-stack for fiduciary markers to be used in map registration. For blood vessel images, rats were given subcutaneous injections of SR101 (Sigma-Aldrich REFREF) for visualization in the red channel. If blood vessel images were unavailable, the green channel was used for FOV alignment. 

Two-photon blood vessel images were matched to widefield maps offline. We selected matching points between the two views based on uniquely identifiable blood vessels present in both views, then used these points to identify a transformation matrix to warp one into the other. Assignment of two-photon FOVs were validated based on retinotopic maps measured with the same paradigm used for widefield maps of azimuth and elevation. We generated sign maps from the retinotopic maps with a series of morphological filters\cite{Marshel2011, Garrett2014, Zhuang2017}, which were then used to identify patches representing putative visual areas (Supp Figure? REFREF). Only two-photon FOVs with matches to widefield maps and unambiguous sign reversals were included for subsequent analyses. 

%%%%

Visual stimulation
Retinotopic mapping (area ID)
Receptive field mapping (visual field targeting)
Object stimuli

Data acquisition
Visual stimuli, synced to two-photon acquisition, ScanImage vX.X (REFREF). 
Synced also to face-tracker camera.
Image preprocessing
stuff
Cell mask identification
stuff
Time course extraction and correction
Stuff

Selectivity and tolerance metrics
Neuronal selectivity to morphs was quantified by a morph tuning index (Rainer1998, Zoccolan2007), MT=n-Ri/Rmax/n-1, where Ri is a neuron’s response to the ith morph, Rmaxis the maximum response amongst the morphs, and nis the number morphs. As a measure of response sparseness, MT ranges from 0 (no shape selectivity) to 1 (maximally shape selective). Size tolerance was quantified by normalizing size tuning curves to their maximum values, then averaging those resulting values that were < 1, that is, ST=Rtest/maxRtest, where Rtestis the mean response to a given test size of a neuron’s most preferred object, and . denotes the average across tested sizes where Rtest<maxRtest. 
Population readout
Discriminability
To quantify discriminability (Figure 5b), we trained linear classifiers (support vector machines) to discriminate the two original objects from the neural activity in each area {\fig:Figure5). The linear-readout scheme is important in that it is a simple, biologically plausible processing step that amounts to a thresholded sum taken over weighted synapses {\cite}. This classifier approach does not provide a measure for the total information present in the population, but rather estimates the lower bound on the information explicitly accessible to the population to support the visual task {\cite everyone, Hung2005, Rust2010, etc etc). 

Linear support vector machines (SVMs) were trained to discriminate object A from object B from neural responses. Each presentation of an image produced a population response vector x of size Nx1, such that repeated presentations form a cluster of points in N- dimensional space (Figure 5a, left). The linear readout amounts to finding a linear hyperplane that best separates the response clouds corresponding to each image from those corresponding to all other images. Specifically, the linear readout amounts to: f(x)=wTx + b, where w is a Nx1 vector of the linear weights applied to each of N neurons (defines the orientation of the hyperplane), and b is a scalar that offsets the hyperplane from the origin. To determine the population’s choice about which image was presented, a response vector x (population response to one image) was applied to the classifier, and negative values of f(x) indicate object A and positive values indicate object B. Performance was defined as the proportion of correct answers when asked to classify each image with a held-out test set never included in training. 
The hyperplane and threshold for each classifier was determined by a support vector machine (SVM) using the scikit-learn machine learning library (LinearSVC, version REFREF, cite Pedregosa?). The data were split into train and test sets (20%) after balancing numbers of samples per condition. We used a 5-fold cross-validation procedure on the train set to fit and evaluate each model:  of the trials partitioned for training, models were optimized where the best C={10-3, 10-2, 10-1, 1, 10, 102, 103}that yielded the highest accuracy was chosen. Performance was then assessed with the held-out test set. 
Linear separability and generalization
To test linear separability (Figure 5c), 80% of the trials corresponding to object A and object B for each size were simultaneously combined to train and evaluate the models, while the remaining 20% of trials was used to measure classifier performance. 
To test generalization, two regimes were used. In the first, “Train one, test one” (Figure 5d-e), each classifier was trained to classify object A and B at one of the 5 sizes, then tested on each of the remaining 4 untrained sizes. Each training set (for each size) included 80% of the trials for a given size, while the test sets could contain either the remaining 20% of trials of the same size (test accuracy on “trained” conditions) or 100% of the trials at one of the other sizes (test accuracy on “novel” conditions). 
In the second regime, “Train a subset, test one” (Figure 5f),  each classifier was trained with trials of  4 of the 5 sizes together, then tested with the remaining, untrained size. Each training set was composed of 80% of trials at each of the 4 train sizes. The remaining 20% of trials for each of the 4 train sizes combined to form the held-out test set (test accuracy on “trained” conditions), while 100% of the trials of the remaining 5th size formed the other type of test (test accuracy on “novel” conditions). All combinations of 4 of 5 sizes were used to train different classifiers and test generalization performance on samples of the remaining 5th size.
Population sampling
In analyses in which a given metric, e.g,. classifier accuracy, is presented as a function of the number of neurons in a pseudo-population, we applied a resampling procedure to measure the variability that can be attributed to the particular subpopulation of neurons or particular subset of trials used for training versus testing. On each iteration, we sampled a new subpopulation of neurons that were randomly selected (without replacement) from all cells aggregated across imaging sites and animals, for a given visual area, and trials were randomly assigned for training and testing (without replacement). Error bars were calculated as the SD of classifier performance across 100 iterations. Chance performance was computed by randomly assigning objects or images associated with each response vector and repeating the classification analysis.

Estimation of tuning preferences in cell bodies
Estimation of cells with significant visual responses
stuff
Estimation of retinotopic preferences in cell bodies and neuropil
Preferred retinotopic location 
stuff
Retinotopic responses of neuropil surround cell bodies
The center of each neuropil ring was assigned the value corresponding to the preferred retinotopic location of that neuropil ring, a disk of 10um radius was dilated from the center. Overlapping disks were averaged for preferred retinotopy. The final pixe-wise estimates were the result of spatially smoothing with (ndimage.gaussian_filter, sigma=7 → microns). 

Rate of retinotopic change -- methods from Liang et al., Cell 2018. - “rate of retinotopic change” for smoothed retinotopic map.


Estimation of receptive fields 


Quantification and statistical analysis
(or, does this go with each specific analysis section?)

Estimation
